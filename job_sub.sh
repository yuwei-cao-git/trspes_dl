#!/bin/bash
#SBATCH --nodes=1               # number of nodes
#SBATCH --cpus-per-task=8       # number of threads per task
#SBATCH --gres=gpu:4            # number of gpus per node
#SBATCH --job-name="test multi-gpu"
#SBATCH --time=00:5:00        # Specify run time 
#SBATCH --output=%N-%j.out    # Specify output file format generated by python script 
#SBATCH --mail-user=yuwei.cao@ubc.ca    # Request email notifications
#SBATCH --mail-type=ALL

#****** NOTE: Need to specify NUM_GPU (and CPU number) in three places 
#             1) above in the "--gpus-per-node=" (or alternative) field 
#             2) update ""--cpus-per-task" above to match the num GPUS ?
#             3) below var named NUM_GPU. 
NUM_GPU=4

# Load python module, and additional required modules
module purge 
module load python/3.10.12 scipy-stack

# Create a new envirionmnet
virtualenv --no-download $SLURM_TMPDIR/venv

# Load an existing environment
source $SLURM_TMPDIR/venv/bin/activate

pip install --no-index --upgrade pip
pip install --no-index -r $PROJECT_HOME/requirements.txt

export PROJECT_HOME= 
export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK

#Set the number of GPUs in python script for ray
export RAY_NUM_GPU=$NUM_GPU

# Set environment variables
export NCCL_BLOCKING_WAIT=1  #Set this environment variable if you wish to use the NCCL backend for inter-GPU communication.
export MASTER_ADDR=$(hostname) #Store the master nodeâ€™s IP address in the MASTER_ADDR environment variable.

#Get the current datetime and export to python script
export DATETIME=`date +%Y_%m_%d_%H_%M_%S`

# Start a single node ray cluster before calling the Python script
ray start --head --node-ip-address="$MASTER_ADDR" --port=34567 --num-cpus=$NUM_GPU --num-gpus=$NUM_GPU --block &

# Wait 10 seconds for ray setup
sleep 10
  
#Print (echo) info to output file
echo "r$SLURM_NODEID master: $MASTER_ADDR"
echo "r$SLURM_NODEID Launching raytune DDP script"

#Run python script
python $PROJECT_HOME/train.py #Train model once